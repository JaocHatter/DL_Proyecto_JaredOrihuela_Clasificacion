{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7166601,"sourceType":"datasetVersion","datasetId":4107330}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Proyecto Final de Deep Learning\n\n### Presentación\n\n* **Título:** Detección de Vehículos desde Vistas Aéreas: Comparativa de los Modelos YOLOv12 y RT-DETR\n* **Autor:** Jared Orihuela Contreras\n* **Afiliación:** Phaw AI 2025 - Curso de Deep Learning\n\n---\n\n### Introducción\n\nEste proyecto se centra en la **detección de vehículos desde una perspectiva aérea**, una tarea fundamental en aplicaciones como la monitorización del tráfico y la planificación urbana. El objetivo principal es evaluar y comparar el rendimiento de dos arquitecturas de última generación: **YOLOv12** y **RT-DETR**. La evaluación se llevará a cabo en un **conjunto de datos personalizado**, el cual se compone de 626 imágenes con anotaciones específicas para la clase 'Vehículo'.\n\nEl estudio se enfocará en comparar los modelos en términos de métricas clave como la **precisión media promedio (mAP)**, **precisión y _recall_**, y la **velocidad de inferencia**. Se evaluarán tres versiones de modelos: YOLOv12 entrenado desde cero, YOLOv12 con _fine-tuning_ y RT-DETR con _fine-tuning_. La meta es determinar qué modelo ofrece el mejor equilibrio entre precisión y eficiencia para la detección de vehículos en este escenario. El proyecto culminará con una presentación de resultados mediante tablas y gráficos comparativos, identificando el modelo con el mejor desempeño.","metadata":{"execution":{"iopub.status.busy":"2025-08-29T00:28:05.581980Z","iopub.execute_input":"2025-08-29T00:28:05.583026Z","iopub.status.idle":"2025-08-29T00:28:05.594374Z","shell.execute_reply.started":"2025-08-29T00:28:05.582989Z","shell.execute_reply":"2025-08-29T00:28:05.593005Z"}}},{"cell_type":"code","source":"!pip install ultralytics torch torchvision numpy matplotlib opencv-python -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:53:40.763121Z","iopub.execute_input":"2025-08-29T18:53:40.763725Z","iopub.status.idle":"2025-08-29T18:55:02.733572Z","shell.execute_reply.started":"2025-08-29T18:53:40.763700Z","shell.execute_reply":"2025-08-29T18:55:02.732758Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import ultralytics\nimport torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport json\nimport os\nimport tqdm\n\nfrom ultralytics import YOLO, RTDETR\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom torch.optim import Adam\nfrom torch.nn import CrossEntropyLoss\nfrom matplotlib.patches import Rectangle\nfrom PIL import Image\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\nfrom torchvision.datasets import CocoDetection\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:55:02.735183Z","iopub.execute_input":"2025-08-29T18:55:02.735432Z","iopub.status.idle":"2025-08-29T18:55:09.393917Z","shell.execute_reply.started":"2025-08-29T18:55:02.735410Z","shell.execute_reply":"2025-08-29T18:55:09.393279Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Preparación de Data\n---\nCabe recalcar que para este proyecto evaluaremos las capacidades del modelos sobre los datos de validación, debido a que en el Dataset no se tiene los labels de la data de testeo.","metadata":{}},{"cell_type":"code","source":"instance_y = \"/kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/train/images\"\ninstance_x = \"/kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/train/images\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:55:09.394602Z","iopub.execute_input":"2025-08-29T18:55:09.394904Z","iopub.status.idle":"2025-08-29T18:55:09.399233Z","shell.execute_reply.started":"2025-08-29T18:55:09.394887Z","shell.execute_reply":"2025-08-29T18:55:09.398444Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Evaluación","metadata":{}},{"cell_type":"markdown","source":"### Métricas clave\n\nPara evaluar el rendimiento de un modelo de detección de objetos, se utilizan métricas específicas que miden tanto la precisión de la caja como la clasificación.\n\n* **`mAP@0.5`:** Es la métrica más común. El **mAP** (_mean Average Precision_) te da un puntaje promedio de la precisión del modelo en todas las clases. El `@0.5` significa que una detección se considera correcta si el área de solapamiento entre la caja predicha y la caja real es de al menos\nel 50%.\n\n* **`mAP@[.5:.95]`:** Esta métrica es más estricta. Evalúa el mAP promediando los resultados en diferentes umbrales de solapamiento (IoU), desde 0.5 hasta 0.95, con pasos de 0.05. Es una excelente manera de medir la robustez del modelo.\n\n\n* **`Precisión`:** La precisión responde a la pregunta: **\"De todas las predicciones positivas que hizo mi modelo, ¿cuántas fueron realmente correctas?\"** Se enfoca en la **calidad** de las detecciones. Un modelo con alta precisión tiene pocos **falsos positivos** (predicciones incorrectas). La precisión es crucial en aplicaciones donde las falsas alarmas son costosas o peligrosas, como la detección de enfermedades o la vigilancia.\n\n  **`Fórmula`:** $$Precision = \\frac{True\\ Positives}{True\\ Positives + False\\ Positives}$$\n\n* **`Recall`:** El _recall_ responde a la pregunta: **\"De todos los objetos que realmente existían, ¿cuántos logró detectar mi modelo?\"**, Se enfoca en la **cantidad** de objetos que el modelo es capaz de encontrar. Un modelo con alto _recall_ tiene pocos **falsos negativos** (objetos reales que no fueron detectados). El _recall_ es vital en aplicaciones donde no detectar un objeto es un riesgo mayor, como la detección de peatones en la conducción autónoma o de tumores en imágenes médicas.\n\n  **`Fórmula`:** $$Recall = \\frac{True\\ Positives}{True\\ Positives + False\\ Negatives}$$\n\n* **`Velocidad de inferencia`:** Mide el número de imágenes que el modelo puede procesar por segundo. Es una métrica crítica, especialmente para proyectos que requieren ser rápidos.\n","metadata":{}},{"cell_type":"markdown","source":"---\n**IMPORTANTE!**\nPara los siguientes modelos se necesitará un \"yaml\" file, con la información de los Dataset, es requerido por los modelos provenientes de la libreria Ultralytics","metadata":{}},{"cell_type":"code","source":"coco_file = \"/kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/data.yaml\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:55:09.400945Z","iopub.execute_input":"2025-08-29T18:55:09.401576Z","iopub.status.idle":"2025-08-29T18:55:09.417305Z","shell.execute_reply.started":"2025-08-29T18:55:09.401530Z","shell.execute_reply":"2025-08-29T18:55:09.416680Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### YOLO V12 (2025)","metadata":{}},{"cell_type":"code","source":"yolo_model = \"yolo12s\"\nyolo12_model = YOLO(yolo_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:17:31.979611Z","iopub.execute_input":"2025-08-29T19:17:31.980190Z","iopub.status.idle":"2025-08-29T19:17:33.586333Z","shell.execute_reply.started":"2025-08-29T19:17:31.980165Z","shell.execute_reply":"2025-08-29T19:17:33.585495Z"}},"outputs":[{"name":"stdout","text":"\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12s.pt to 'yolo12s.pt': 100% ━━━━━━━━━━━━ 18.1/18.1MB 25.7MB/s 0.7s\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"yolo12_metrics = yolo12_model.val(data = coco_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:29:25.484821Z","iopub.execute_input":"2025-08-29T19:29:25.485645Z","iopub.status.idle":"2025-08-29T19:29:32.655574Z","shell.execute_reply.started":"2025-08-29T19:29:25.485613Z","shell.execute_reply":"2025-08-29T19:29:32.654660Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.189 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLOv12s summary (fused): 159 layers, 9,261,840 parameters, 0 gradients, 21.4 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.5±0.2 ms, read: 146.7±44.0 MB/s, size: 53.2 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid/labels... 90 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 90/90 994.2it/s 0.1ss\nWARNING ⚠️ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid is not writeable, cache not saved.\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 1.9it/s 3.1ss\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all         90        937     0.0268       0.08     0.0145    0.00816\n                person         90        937     0.0268       0.08     0.0145    0.00816\nSpeed: 3.8ms preprocess, 12.5ms inference, 0.0ms loss, 9.7ms postprocess per image\nResults saved to \u001b[1mruns/detect/val\u001b[0m\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(yolo12_metrics.results_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:29:34.815629Z","iopub.execute_input":"2025-08-29T19:29:34.815951Z","iopub.status.idle":"2025-08-29T19:29:34.820895Z","shell.execute_reply.started":"2025-08-29T19:29:34.815926Z","shell.execute_reply":"2025-08-29T19:29:34.820194Z"}},"outputs":[{"name":"stdout","text":"{'metrics/precision(B)': 0.02682403433476395, 'metrics/recall(B)': 0.08004268943436499, 'metrics/mAP50(B)': 0.014511753874476126, 'metrics/mAP50-95(B)': 0.008158172055664884, 'fitness': 0.008793530237546008}\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"### YOLO V12 (Finetunned)","metadata":{}},{"cell_type":"code","source":"yolo12_finetuned_model = YOLO(yolo_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:17:43.062284Z","iopub.execute_input":"2025-08-29T19:17:43.062597Z","iopub.status.idle":"2025-08-29T19:17:43.138480Z","shell.execute_reply.started":"2025-08-29T19:17:43.062575Z","shell.execute_reply":"2025-08-29T19:17:43.137725Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"results_yolov12_train = yolo12_finetuned_model.train(data = coco_file, epochs = 10, imgsz = 640, batch = 4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:17:46.607829Z","iopub.execute_input":"2025-08-29T19:17:46.608517Z","iopub.status.idle":"2025-08-29T19:22:19.652789Z","shell.execute_reply.started":"2025-08-29T19:17:46.608490Z","shell.execute_reply":"2025-08-29T19:22:19.651960Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.189 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n 21        [14, 17, 20]  1    819795  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \nYOLOv12s summary: 272 layers, 9,253,523 parameters, 9,253,507 gradients, 21.5 GFLOPs\n\nTransferred 685/691 items from pretrained weights\nFreezing layer 'model.21.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.4±0.0 ms, read: 138.4±28.6 MB/s, size: 57.5 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/train/labels... 536 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 536/536 862.3it/s 0.6s\nWARNING ⚠️ \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/train is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.5±0.2 ms, read: 107.8±19.8 MB/s, size: 57.6 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid/labels... 90 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 90/90 489.6it/s 0.2s\nWARNING ⚠️ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid is not writeable, cache not saved.\nPlotting labels to runs/detect/train3/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train3\u001b[0m\nStarting training for 10 epochs...\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       1/10      2.64G      1.253      1.224      1.155         21        640: 100% ━━━━━━━━━━━━ 134/134 5.1it/s 26.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.8it/s 1.2s\n                   all         90        937      0.825      0.828      0.887      0.574\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       2/10      2.64G      1.262     0.8955      1.163         36        640: 100% ━━━━━━━━━━━━ 134/134 5.4it/s 24.7s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 11.0it/s 1.1s\n                   all         90        937      0.837      0.813      0.872       0.58\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       3/10      2.64G      1.294     0.9661      1.191         63        640: 100% ━━━━━━━━━━━━ 134/134 5.5it/s 24.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.7it/s 1.1s\n                   all         90        937      0.836      0.864      0.924      0.611\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       4/10      2.64G      1.215     0.8314      1.159         45        640: 100% ━━━━━━━━━━━━ 134/134 5.5it/s 24.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 11.0it/s 1.1s\n                   all         90        937       0.86      0.868      0.939      0.639\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       5/10      2.64G      1.181     0.7543      1.126         52        640: 100% ━━━━━━━━━━━━ 134/134 5.5it/s 24.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 11.1it/s 1.1s\n                   all         90        937      0.871      0.895      0.944      0.653\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       6/10      2.68G      1.159     0.7358      1.113         31        640: 100% ━━━━━━━━━━━━ 134/134 5.5it/s 24.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 11.3it/s 1.1s\n                   all         90        937      0.878      0.858      0.931      0.642\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       7/10      2.73G      1.111     0.6543      1.088         29        640: 100% ━━━━━━━━━━━━ 134/134 5.5it/s 24.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 11.1it/s 1.1s\n                   all         90        937       0.85      0.919      0.957      0.681\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       8/10      2.79G      1.095     0.6304      1.089         64        640: 100% ━━━━━━━━━━━━ 134/134 5.5it/s 24.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 11.2it/s 1.1s\n                   all         90        937      0.877      0.922      0.952      0.682\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       9/10      2.84G      1.058      0.591      1.059         47        640: 100% ━━━━━━━━━━━━ 134/134 5.5it/s 24.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 11.3it/s 1.1s\n                   all         90        937      0.873      0.934      0.964      0.702\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      10/10       2.9G      1.042     0.5651      1.062          9        640: 100% ━━━━━━━━━━━━ 134/134 5.5it/s 24.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 11.5it/s 1.0s\n                   all         90        937       0.89      0.932      0.967      0.706\n\n10 epochs completed in 0.073 hours.\nOptimizer stripped from runs/detect/train3/weights/last.pt, 18.9MB\nOptimizer stripped from runs/detect/train3/weights/best.pt, 18.9MB\n\nValidating runs/detect/train3/weights/best.pt...\nUltralytics 8.3.189 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLOv12s summary (fused): 159 layers, 9,231,267 parameters, 0 gradients, 21.2 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 6.0it/s 2.0s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all         90        937       0.89      0.931      0.967      0.706\nSpeed: 0.2ms preprocess, 9.1ms inference, 0.0ms loss, 1.4ms postprocess per image\nResults saved to \u001b[1mruns/detect/train3\u001b[0m\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"yolo12_finetuned_metrics = yolo12_finetuned_model.val(data = coco_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:23:52.799028Z","iopub.execute_input":"2025-08-29T19:23:52.800072Z","iopub.status.idle":"2025-08-29T19:23:57.967179Z","shell.execute_reply.started":"2025-08-29T19:23:52.800035Z","shell.execute_reply":"2025-08-29T19:23:57.966279Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.189 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLOv12s summary (fused): 159 layers, 9,231,267 parameters, 0 gradients, 21.2 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 1.2±0.7 ms, read: 100.1±42.6 MB/s, size: 61.7 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid/labels... 90 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 90/90 950.4it/s 0.1s\nWARNING ⚠️ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid is not writeable, cache not saved.\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 23/23 12.3it/s 1.9s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all         90        937       0.89      0.931      0.967      0.706\nSpeed: 0.9ms preprocess, 15.2ms inference, 0.0ms loss, 1.1ms postprocess per image\nResults saved to \u001b[1mruns/detect/train32\u001b[0m\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"yolo12_finetuned_metrics.results_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:29:04.906220Z","iopub.execute_input":"2025-08-29T19:29:04.906602Z","iopub.status.idle":"2025-08-29T19:29:04.913109Z","shell.execute_reply.started":"2025-08-29T19:29:04.906560Z","shell.execute_reply":"2025-08-29T19:29:04.912454Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'metrics/precision(B)': 0.8898066505206459,\n 'metrics/recall(B)': 0.9307316265221801,\n 'metrics/mAP50(B)': 0.9672328277319089,\n 'metrics/mAP50-95(B)': 0.7057710848472812,\n 'fitness': 0.731917259135744}"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"### RT-DETR (2023)","metadata":{}},{"cell_type":"code","source":"rtdetr_finetuned_model = RTDETR(\"rtdetr-l.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:55:09.418040Z","iopub.execute_input":"2025-08-29T18:55:09.418303Z","iopub.status.idle":"2025-08-29T18:55:13.994136Z","shell.execute_reply.started":"2025-08-29T18:55:09.418278Z","shell.execute_reply":"2025-08-29T18:55:13.993501Z"}},"outputs":[{"name":"stdout","text":"\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/rtdetr-l.pt to 'rtdetr-l.pt': 100% ━━━━━━━━━━━━ 63.4/63.4MB 30.6MB/s 2.1s\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"results_rtdetr_train = rtdetr_finetuned_model.train(data = coco_file, epochs=10, imgsz=640, batch = 4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:55:19.609622Z","iopub.execute_input":"2025-08-29T18:55:19.610339Z","iopub.status.idle":"2025-08-29T19:06:10.630498Z","shell.execute_reply.started":"2025-08-29T18:55:19.610314Z","shell.execute_reply":"2025-08-29T19:06:10.629769Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.189 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1/755.1KB 3.4MB/s 0.2ss\nOverriding model.yaml nc=80 with nc=1\nWARNING ⚠️ no model scale passed. Assuming scale='l'.\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 28        [21, 24, 27]  1   7303907  ultralytics.nn.modules.head.RTDETRDecoder    [1, [256, 256, 256]]          \nrt-detr-l summary: 457 layers, 32,808,131 parameters, 32,808,131 gradients, 108.0 GFLOPs\n\nTransferred 926/941 items from pretrained weights\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4/5.4MB 15.5MB/s 0.3ss\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 10.8±1.7 MB/s, size: 57.5 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/train/labels... 536 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 536/536 191.6it/s 2.8s\nWARNING ⚠️ \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/train is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 7.7±2.1 MB/s, size: 57.6 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid/labels... 90 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 90/90 153.2it/s 0.6s\nWARNING ⚠️ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid is not writeable, cache not saved.\nPlotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.0005), 226 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 10 epochs...\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       1/10       3.4G      1.314      1.878     0.4056         43        640:   0% ──────────── 0/134  1.6s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       1/10      3.56G     0.5137     0.8122     0.1338         21        640: 100% ━━━━━━━━━━━━ 134/134 2.2it/s 1:02s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.0it/s 3.0s\n                   all         90        937       0.83      0.851      0.894      0.632\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       2/10      3.84G     0.3512     0.4228    0.09535         49        640:   0% ──────────── 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       2/10      3.84G     0.3437     0.4431    0.07475         36        640: 100% ━━━━━━━━━━━━ 134/134 2.3it/s 59.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 5.5it/s 2.2s\n                   all         90        937      0.857       0.92      0.939      0.694\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       3/10      3.93G     0.3503     0.4772    0.08357         46        640:   0% ──────────── 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       3/10      3.93G     0.3337     0.4286    0.06864         63        640: 100% ━━━━━━━━━━━━ 134/134 2.3it/s 58.7s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 5.5it/s 2.2s\n                   all         90        937      0.863       0.89      0.933       0.69\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       4/10      4.14G     0.2735     0.4181    0.06352         31        640:   0% ──────────── 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       4/10      4.14G     0.3194     0.4119    0.06847         45        640: 100% ━━━━━━━━━━━━ 134/134 2.3it/s 58.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 5.5it/s 2.2s\n                   all         90        937      0.868      0.916      0.952      0.685\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       5/10      4.23G     0.2661     0.3997    0.06427         22        640:   0% ──────────── 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       5/10       4.3G     0.3154     0.4079    0.06587         52        640: 100% ━━━━━━━━━━━━ 134/134 2.3it/s 58.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 5.5it/s 2.2s\n                   all         90        937      0.878      0.885      0.934      0.699\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       6/10      4.44G     0.3234     0.4205    0.06482         29        640:   0% ──────────── 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       6/10      4.49G     0.3072      0.402    0.06424         31        640: 100% ━━━━━━━━━━━━ 134/134 2.3it/s 58.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 5.5it/s 2.2s\n                   all         90        937      0.869      0.918      0.947      0.704\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       7/10      4.62G     0.2837     0.3742    0.07271         43        640:   0% ──────────── 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       7/10      4.67G     0.2943     0.3968    0.05961         29        640: 100% ━━━━━━━━━━━━ 134/134 2.3it/s 58.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 5.5it/s 2.2s\n                   all         90        937      0.844      0.945      0.938      0.698\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       8/10      4.88G     0.3725     0.3897    0.05988         48        640:   0% ──────────── 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       8/10      4.89G     0.2922      0.393    0.05924         64        640: 100% ━━━━━━━━━━━━ 134/134 2.3it/s 58.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 5.5it/s 2.2s\n                   all         90        937      0.868      0.903      0.936      0.704\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       9/10      4.92G     0.3045     0.4325     0.0748         23        640:   0% ──────────── 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       9/10      5.06G     0.2833     0.3822    0.05624         47        640: 100% ━━━━━━━━━━━━ 134/134 2.3it/s 58.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 5.5it/s 2.2s\n                   all         90        937      0.878      0.926      0.948      0.718\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K      10/10       5.2G     0.2679     0.3567    0.06253         41        640:   0% ──────────── 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K      10/10      5.25G     0.2833     0.3786    0.05978          9        640: 100% ━━━━━━━━━━━━ 134/134 2.3it/s 58.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 5.5it/s 2.2s\n                   all         90        937      0.881       0.92      0.939      0.714\n\n10 epochs completed in 0.174 hours.\nOptimizer stripped from runs/detect/train/weights/last.pt, 66.1MB\nOptimizer stripped from runs/detect/train/weights/best.pt, 66.1MB\n\nValidating runs/detect/train/weights/best.pt...\nUltralytics 8.3.189 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nrt-detr-l summary: 302 layers, 31,985,795 parameters, 0 gradients, 103.4 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 3.9it/s 3.1s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all         90        937      0.877      0.926      0.948      0.718\nSpeed: 0.2ms preprocess, 30.5ms inference, 0.0ms loss, 0.4ms postprocess per image\nResults saved to \u001b[1mruns/detect/train\u001b[0m\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!zip -r train.zip /kaggle/working/runs/detect/train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:08:49.208049Z","iopub.execute_input":"2025-08-29T19:08:49.208811Z","iopub.status.idle":"2025-08-29T19:08:55.772920Z","shell.execute_reply.started":"2025-08-29T19:08:49.208765Z","shell.execute_reply":"2025-08-29T19:08:55.772129Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/runs/detect/train/ (stored 0%)\n  adding: kaggle/working/runs/detect/train/results.png (deflated 7%)\n  adding: kaggle/working/runs/detect/train/BoxP_curve.png (deflated 16%)\n  adding: kaggle/working/runs/detect/train/BoxF1_curve.png (deflated 15%)\n  adding: kaggle/working/runs/detect/train/args.yaml (deflated 52%)\n  adding: kaggle/working/runs/detect/train/train_batch2.jpg (deflated 4%)\n  adding: kaggle/working/runs/detect/train/val_batch1_pred.jpg (deflated 2%)\n  adding: kaggle/working/runs/detect/train/train_batch1.jpg (deflated 8%)\n  adding: kaggle/working/runs/detect/train/results.csv (deflated 60%)\n  adding: kaggle/working/runs/detect/train/weights/ (stored 0%)\n  adding: kaggle/working/runs/detect/train/weights/last.pt (deflated 8%)\n  adding: kaggle/working/runs/detect/train/weights/best.pt (deflated 8%)\n  adding: kaggle/working/runs/detect/train/val_batch0_pred.jpg (deflated 1%)\n  adding: kaggle/working/runs/detect/train/labels.jpg (deflated 34%)\n  adding: kaggle/working/runs/detect/train/val_batch2_labels.jpg (deflated 2%)\n  adding: kaggle/working/runs/detect/train/confusion_matrix_normalized.png (deflated 37%)\n  adding: kaggle/working/runs/detect/train/confusion_matrix.png (deflated 36%)\n  adding: kaggle/working/runs/detect/train/val_batch1_labels.jpg (deflated 2%)\n  adding: kaggle/working/runs/detect/train/val_batch0_labels.jpg (deflated 2%)\n  adding: kaggle/working/runs/detect/train/BoxR_curve.png (deflated 16%)\n  adding: kaggle/working/runs/detect/train/BoxPR_curve.png (deflated 24%)\n  adding: kaggle/working/runs/detect/train/train_batch0.jpg (deflated 7%)\n  adding: kaggle/working/runs/detect/train/val_batch2_pred.jpg (deflated 1%)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"rtdetr_metrics = rtdetr_finetuned_model.val(data = coco_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:10:53.862612Z","iopub.execute_input":"2025-08-29T19:10:53.863366Z","iopub.status.idle":"2025-08-29T19:11:01.734941Z","shell.execute_reply.started":"2025-08-29T19:10:53.863344Z","shell.execute_reply":"2025-08-29T19:11:01.734268Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.189 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nrt-detr-l summary: 302 layers, 31,985,795 parameters, 0 gradients, 103.4 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.4±0.0 ms, read: 136.6±34.2 MB/s, size: 61.7 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid/labels... 90 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 90/90 994.5it/s 0.1ss\nWARNING ⚠️ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid is not writeable, cache not saved.\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 23/23 7.6it/s 3.0s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all         90        937      0.877      0.926      0.948      0.719\nSpeed: 1.4ms preprocess, 27.7ms inference, 0.0ms loss, 0.5ms postprocess per image\nResults saved to \u001b[1mruns/detect/train2\u001b[0m\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"rtdetr_metrics.results_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:11:32.716011Z","iopub.execute_input":"2025-08-29T19:11:32.716310Z","iopub.status.idle":"2025-08-29T19:11:32.723268Z","shell.execute_reply.started":"2025-08-29T19:11:32.716287Z","shell.execute_reply":"2025-08-29T19:11:32.722718Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'metrics/precision(B)': 0.8771930562193498,\n 'metrics/recall(B)': 0.9263607257203842,\n 'metrics/mAP50(B)': 0.9482223044288002,\n 'metrics/mAP50-95(B)': 0.7194915127172211,\n 'fitness': 0.742364591888379}"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}