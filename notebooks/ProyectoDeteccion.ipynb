{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7166601,"sourceType":"datasetVersion","datasetId":4107330}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Proyecto Final de Deep Learning\n\n### PresentaciÃ³n\n\n* **TÃ­tulo:** DetecciÃ³n de VehÃ­culos desde Vistas AÃ©reas: Comparativa de los Modelos YOLOv12 y RT-DETR\n* **Autor:** Jared Orihuela Contreras\n* **AfiliaciÃ³n:** Phaw AI 2025 - Curso de Deep Learning\n\n---\n\n### IntroducciÃ³n\n\nEste proyecto se centra en la **detecciÃ³n de vehÃ­culos desde una perspectiva aÃ©rea**, una tarea fundamental en aplicaciones como la monitorizaciÃ³n del trÃ¡fico y la planificaciÃ³n urbana. El objetivo principal es evaluar y comparar el rendimiento de dos arquitecturas de Ãºltima generaciÃ³n: **YOLOv12** y **RT-DETR**. La evaluaciÃ³n se llevarÃ¡ a cabo en un **conjunto de datos personalizado**, el cual se compone de 626 imÃ¡genes con anotaciones especÃ­ficas para la clase 'VehÃ­culo'.\n\nEl estudio se enfocarÃ¡ en comparar los modelos en tÃ©rminos de mÃ©tricas clave como la **precisiÃ³n media promedio (mAP)**, **precisiÃ³n y _recall_**, y la **velocidad de inferencia**. Se evaluarÃ¡n tres versiones de modelos: YOLOv12 entrenado desde cero, YOLOv12 con _fine-tuning_ y RT-DETR con _fine-tuning_. La meta es determinar quÃ© modelo ofrece el mejor equilibrio entre precisiÃ³n y eficiencia para la detecciÃ³n de vehÃ­culos en este escenario. El proyecto culminarÃ¡ con una presentaciÃ³n de resultados mediante tablas y grÃ¡ficos comparativos, identificando el modelo con el mejor desempeÃ±o.","metadata":{"execution":{"iopub.status.busy":"2025-08-29T00:28:05.581980Z","iopub.execute_input":"2025-08-29T00:28:05.583026Z","iopub.status.idle":"2025-08-29T00:28:05.594374Z","shell.execute_reply.started":"2025-08-29T00:28:05.582989Z","shell.execute_reply":"2025-08-29T00:28:05.593005Z"}}},{"cell_type":"code","source":"!pip install ultralytics torch torchvision numpy matplotlib opencv-python -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:53:40.763121Z","iopub.execute_input":"2025-08-29T18:53:40.763725Z","iopub.status.idle":"2025-08-29T18:55:02.733572Z","shell.execute_reply.started":"2025-08-29T18:53:40.763700Z","shell.execute_reply":"2025-08-29T18:55:02.732758Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import ultralytics\nimport torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport json\nimport os\nimport tqdm\n\nfrom ultralytics import YOLO, RTDETR\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom torch.optim import Adam\nfrom torch.nn import CrossEntropyLoss\nfrom matplotlib.patches import Rectangle\nfrom PIL import Image\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\nfrom torchvision.datasets import CocoDetection\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:55:02.735183Z","iopub.execute_input":"2025-08-29T18:55:02.735432Z","iopub.status.idle":"2025-08-29T18:55:09.393917Z","shell.execute_reply.started":"2025-08-29T18:55:02.735410Z","shell.execute_reply":"2025-08-29T18:55:09.393279Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file âœ… \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## PreparaciÃ³n de Data\n---\nCabe recalcar que para este proyecto evaluaremos las capacidades del modelos sobre los datos de validaciÃ³n, debido a que en el Dataset no se tiene los labels de la data de testeo.","metadata":{}},{"cell_type":"code","source":"instance_y = \"/kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/train/images\"\ninstance_x = \"/kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/train/images\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:55:09.394602Z","iopub.execute_input":"2025-08-29T18:55:09.394904Z","iopub.status.idle":"2025-08-29T18:55:09.399233Z","shell.execute_reply.started":"2025-08-29T18:55:09.394887Z","shell.execute_reply":"2025-08-29T18:55:09.398444Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## EvaluaciÃ³n","metadata":{}},{"cell_type":"markdown","source":"### MÃ©tricas clave\n\nPara evaluar el rendimiento de un modelo de detecciÃ³n de objetos, se utilizan mÃ©tricas especÃ­ficas que miden tanto la precisiÃ³n de la caja como la clasificaciÃ³n.\n\n* **`mAP@0.5`:** Es la mÃ©trica mÃ¡s comÃºn. El **mAP** (_mean Average Precision_) te da un puntaje promedio de la precisiÃ³n del modelo en todas las clases. El `@0.5` significa que una detecciÃ³n se considera correcta si el Ã¡rea de solapamiento entre la caja predicha y la caja real es de al menos\nel 50%.\n\n* **`mAP@[.5:.95]`:** Esta mÃ©trica es mÃ¡s estricta. EvalÃºa el mAP promediando los resultados en diferentes umbrales de solapamiento (IoU), desde 0.5 hasta 0.95, con pasos de 0.05. Es una excelente manera de medir la robustez del modelo.\n\n\n* **`PrecisiÃ³n`:** La precisiÃ³n responde a la pregunta: **\"De todas las predicciones positivas que hizo mi modelo, Â¿cuÃ¡ntas fueron realmente correctas?\"** Se enfoca en la **calidad** de las detecciones. Un modelo con alta precisiÃ³n tiene pocos **falsos positivos** (predicciones incorrectas). La precisiÃ³n es crucial en aplicaciones donde las falsas alarmas son costosas o peligrosas, como la detecciÃ³n de enfermedades o la vigilancia.\n\n  **`FÃ³rmula`:** $$Precision = \\frac{True\\ Positives}{True\\ Positives + False\\ Positives}$$\n\n* **`Recall`:** El _recall_ responde a la pregunta: **\"De todos los objetos que realmente existÃ­an, Â¿cuÃ¡ntos logrÃ³ detectar mi modelo?\"**, Se enfoca en la **cantidad** de objetos que el modelo es capaz de encontrar. Un modelo con alto _recall_ tiene pocos **falsos negativos** (objetos reales que no fueron detectados). El _recall_ es vital en aplicaciones donde no detectar un objeto es un riesgo mayor, como la detecciÃ³n de peatones en la conducciÃ³n autÃ³noma o de tumores en imÃ¡genes mÃ©dicas.\n\n  **`FÃ³rmula`:** $$Recall = \\frac{True\\ Positives}{True\\ Positives + False\\ Negatives}$$\n\n* **`Velocidad de inferencia`:** Mide el nÃºmero de imÃ¡genes que el modelo puede procesar por segundo. Es una mÃ©trica crÃ­tica, especialmente para proyectos que requieren ser rÃ¡pidos.\n","metadata":{}},{"cell_type":"markdown","source":"---\n**IMPORTANTE!**\nPara los siguientes modelos se necesitarÃ¡ un \"yaml\" file, con la informaciÃ³n de los Dataset, es requerido por los modelos provenientes de la libreria Ultralytics","metadata":{}},{"cell_type":"code","source":"coco_file = \"/kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/data.yaml\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:55:09.400945Z","iopub.execute_input":"2025-08-29T18:55:09.401576Z","iopub.status.idle":"2025-08-29T18:55:09.417305Z","shell.execute_reply.started":"2025-08-29T18:55:09.401530Z","shell.execute_reply":"2025-08-29T18:55:09.416680Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### YOLO V12 (2025)","metadata":{}},{"cell_type":"code","source":"yolo_model = \"yolo12s\"\nyolo12_model = YOLO(yolo_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:17:31.979611Z","iopub.execute_input":"2025-08-29T19:17:31.980190Z","iopub.status.idle":"2025-08-29T19:17:33.586333Z","shell.execute_reply.started":"2025-08-29T19:17:31.980165Z","shell.execute_reply":"2025-08-29T19:17:33.585495Z"}},"outputs":[{"name":"stdout","text":"\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12s.pt to 'yolo12s.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 18.1/18.1MB 25.7MB/s 0.7s\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"yolo12_metrics = yolo12_model.val(data = coco_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:29:25.484821Z","iopub.execute_input":"2025-08-29T19:29:25.485645Z","iopub.status.idle":"2025-08-29T19:29:32.655574Z","shell.execute_reply.started":"2025-08-29T19:29:25.485613Z","shell.execute_reply":"2025-08-29T19:29:32.654660Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.189 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLOv12s summary (fused): 159 layers, 9,261,840 parameters, 0 gradients, 21.4 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 146.7Â±44.0 MB/s, size: 53.2 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid/labels... 90 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 994.2it/s 0.1ss\nWARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid is not writeable, cache not saved.\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 6/6 1.9it/s 3.1ss\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all         90        937     0.0268       0.08     0.0145    0.00816\n                person         90        937     0.0268       0.08     0.0145    0.00816\nSpeed: 3.8ms preprocess, 12.5ms inference, 0.0ms loss, 9.7ms postprocess per image\nResults saved to \u001b[1mruns/detect/val\u001b[0m\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(yolo12_metrics.results_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:29:34.815629Z","iopub.execute_input":"2025-08-29T19:29:34.815951Z","iopub.status.idle":"2025-08-29T19:29:34.820895Z","shell.execute_reply.started":"2025-08-29T19:29:34.815926Z","shell.execute_reply":"2025-08-29T19:29:34.820194Z"}},"outputs":[{"name":"stdout","text":"{'metrics/precision(B)': 0.02682403433476395, 'metrics/recall(B)': 0.08004268943436499, 'metrics/mAP50(B)': 0.014511753874476126, 'metrics/mAP50-95(B)': 0.008158172055664884, 'fitness': 0.008793530237546008}\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"### YOLO V12 (Finetunned)","metadata":{}},{"cell_type":"code","source":"yolo12_finetuned_model = YOLO(yolo_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:17:43.062284Z","iopub.execute_input":"2025-08-29T19:17:43.062597Z","iopub.status.idle":"2025-08-29T19:17:43.138480Z","shell.execute_reply.started":"2025-08-29T19:17:43.062575Z","shell.execute_reply":"2025-08-29T19:17:43.137725Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"results_yolov12_train = yolo12_finetuned_model.train(data = coco_file, epochs = 10, imgsz = 640, batch = 4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:17:46.607829Z","iopub.execute_input":"2025-08-29T19:17:46.608517Z","iopub.status.idle":"2025-08-29T19:22:19.652789Z","shell.execute_reply.started":"2025-08-29T19:17:46.608490Z","shell.execute_reply":"2025-08-29T19:22:19.651960Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.189 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n 21        [14, 17, 20]  1    819795  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \nYOLOv12s summary: 272 layers, 9,253,523 parameters, 9,253,507 gradients, 21.5 GFLOPs\n\nTransferred 685/691 items from pretrained weights\nFreezing layer 'model.21.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.0 ms, read: 138.4Â±28.6 MB/s, size: 57.5 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/train/labels... 536 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 536/536 862.3it/s 0.6s\nWARNING âš ï¸ \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/train is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 107.8Â±19.8 MB/s, size: 57.6 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid/labels... 90 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 489.6it/s 0.2s\nWARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid is not writeable, cache not saved.\nPlotting labels to runs/detect/train3/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train3\u001b[0m\nStarting training for 10 epochs...\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       1/10      2.64G      1.253      1.224      1.155         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 5.1it/s 26.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 9.8it/s 1.2s\n                   all         90        937      0.825      0.828      0.887      0.574\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       2/10      2.64G      1.262     0.8955      1.163         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 5.4it/s 24.7s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 11.0it/s 1.1s\n                   all         90        937      0.837      0.813      0.872       0.58\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       3/10      2.64G      1.294     0.9661      1.191         63        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 5.5it/s 24.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 10.7it/s 1.1s\n                   all         90        937      0.836      0.864      0.924      0.611\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       4/10      2.64G      1.215     0.8314      1.159         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 5.5it/s 24.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 11.0it/s 1.1s\n                   all         90        937       0.86      0.868      0.939      0.639\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       5/10      2.64G      1.181     0.7543      1.126         52        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 5.5it/s 24.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 11.1it/s 1.1s\n                   all         90        937      0.871      0.895      0.944      0.653\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       6/10      2.68G      1.159     0.7358      1.113         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 5.5it/s 24.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 11.3it/s 1.1s\n                   all         90        937      0.878      0.858      0.931      0.642\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       7/10      2.73G      1.111     0.6543      1.088         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 5.5it/s 24.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 11.1it/s 1.1s\n                   all         90        937       0.85      0.919      0.957      0.681\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       8/10      2.79G      1.095     0.6304      1.089         64        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 5.5it/s 24.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 11.2it/s 1.1s\n                   all         90        937      0.877      0.922      0.952      0.682\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       9/10      2.84G      1.058      0.591      1.059         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 5.5it/s 24.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 11.3it/s 1.1s\n                   all         90        937      0.873      0.934      0.964      0.702\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      10/10       2.9G      1.042     0.5651      1.062          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 5.5it/s 24.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 11.5it/s 1.0s\n                   all         90        937       0.89      0.932      0.967      0.706\n\n10 epochs completed in 0.073 hours.\nOptimizer stripped from runs/detect/train3/weights/last.pt, 18.9MB\nOptimizer stripped from runs/detect/train3/weights/best.pt, 18.9MB\n\nValidating runs/detect/train3/weights/best.pt...\nUltralytics 8.3.189 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLOv12s summary (fused): 159 layers, 9,231,267 parameters, 0 gradients, 21.2 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 6.0it/s 2.0s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all         90        937       0.89      0.931      0.967      0.706\nSpeed: 0.2ms preprocess, 9.1ms inference, 0.0ms loss, 1.4ms postprocess per image\nResults saved to \u001b[1mruns/detect/train3\u001b[0m\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"yolo12_finetuned_metrics = yolo12_finetuned_model.val(data = coco_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:23:52.799028Z","iopub.execute_input":"2025-08-29T19:23:52.800072Z","iopub.status.idle":"2025-08-29T19:23:57.967179Z","shell.execute_reply.started":"2025-08-29T19:23:52.800035Z","shell.execute_reply":"2025-08-29T19:23:57.966279Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.189 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLOv12s summary (fused): 159 layers, 9,231,267 parameters, 0 gradients, 21.2 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.2Â±0.7 ms, read: 100.1Â±42.6 MB/s, size: 61.7 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid/labels... 90 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 950.4it/s 0.1s\nWARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid is not writeable, cache not saved.\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 12.3it/s 1.9s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all         90        937       0.89      0.931      0.967      0.706\nSpeed: 0.9ms preprocess, 15.2ms inference, 0.0ms loss, 1.1ms postprocess per image\nResults saved to \u001b[1mruns/detect/train32\u001b[0m\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"yolo12_finetuned_metrics.results_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:29:04.906220Z","iopub.execute_input":"2025-08-29T19:29:04.906602Z","iopub.status.idle":"2025-08-29T19:29:04.913109Z","shell.execute_reply.started":"2025-08-29T19:29:04.906560Z","shell.execute_reply":"2025-08-29T19:29:04.912454Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'metrics/precision(B)': 0.8898066505206459,\n 'metrics/recall(B)': 0.9307316265221801,\n 'metrics/mAP50(B)': 0.9672328277319089,\n 'metrics/mAP50-95(B)': 0.7057710848472812,\n 'fitness': 0.731917259135744}"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"### RT-DETR (2023)","metadata":{}},{"cell_type":"code","source":"rtdetr_finetuned_model = RTDETR(\"rtdetr-l.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:55:09.418040Z","iopub.execute_input":"2025-08-29T18:55:09.418303Z","iopub.status.idle":"2025-08-29T18:55:13.994136Z","shell.execute_reply.started":"2025-08-29T18:55:09.418278Z","shell.execute_reply":"2025-08-29T18:55:13.993501Z"}},"outputs":[{"name":"stdout","text":"\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/rtdetr-l.pt to 'rtdetr-l.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 63.4/63.4MB 30.6MB/s 2.1s\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"results_rtdetr_train = rtdetr_finetuned_model.train(data = coco_file, epochs=10, imgsz=640, batch = 4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:55:19.609622Z","iopub.execute_input":"2025-08-29T18:55:19.610339Z","iopub.status.idle":"2025-08-29T19:06:10.630498Z","shell.execute_reply.started":"2025-08-29T18:55:19.610314Z","shell.execute_reply":"2025-08-29T19:06:10.629769Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.189 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1/755.1KB 3.4MB/s 0.2ss\nOverriding model.yaml nc=80 with nc=1\nWARNING âš ï¸ no model scale passed. Assuming scale='l'.\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 28        [21, 24, 27]  1   7303907  ultralytics.nn.modules.head.RTDETRDecoder    [1, [256, 256, 256]]          \nrt-detr-l summary: 457 layers, 32,808,131 parameters, 32,808,131 gradients, 108.0 GFLOPs\n\nTransferred 926/941 items from pretrained weights\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4/5.4MB 15.5MB/s 0.3ss\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 10.8Â±1.7 MB/s, size: 57.5 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/train/labels... 536 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 536/536 191.6it/s 2.8s\nWARNING âš ï¸ \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/train is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 7.7Â±2.1 MB/s, size: 57.6 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid/labels... 90 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 153.2it/s 0.6s\nWARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid is not writeable, cache not saved.\nPlotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.0005), 226 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 10 epochs...\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       1/10       3.4G      1.314      1.878     0.4056         43        640:   0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/134  1.6s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       1/10      3.56G     0.5137     0.8122     0.1338         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 2.2it/s 1:02s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 4.0it/s 3.0s\n                   all         90        937       0.83      0.851      0.894      0.632\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       2/10      3.84G     0.3512     0.4228    0.09535         49        640:   0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       2/10      3.84G     0.3437     0.4431    0.07475         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 2.3it/s 59.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 5.5it/s 2.2s\n                   all         90        937      0.857       0.92      0.939      0.694\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       3/10      3.93G     0.3503     0.4772    0.08357         46        640:   0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       3/10      3.93G     0.3337     0.4286    0.06864         63        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 2.3it/s 58.7s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 5.5it/s 2.2s\n                   all         90        937      0.863       0.89      0.933       0.69\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       4/10      4.14G     0.2735     0.4181    0.06352         31        640:   0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       4/10      4.14G     0.3194     0.4119    0.06847         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 2.3it/s 58.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 5.5it/s 2.2s\n                   all         90        937      0.868      0.916      0.952      0.685\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       5/10      4.23G     0.2661     0.3997    0.06427         22        640:   0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       5/10       4.3G     0.3154     0.4079    0.06587         52        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 2.3it/s 58.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 5.5it/s 2.2s\n                   all         90        937      0.878      0.885      0.934      0.699\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       6/10      4.44G     0.3234     0.4205    0.06482         29        640:   0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       6/10      4.49G     0.3072      0.402    0.06424         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 2.3it/s 58.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 5.5it/s 2.2s\n                   all         90        937      0.869      0.918      0.947      0.704\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       7/10      4.62G     0.2837     0.3742    0.07271         43        640:   0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       7/10      4.67G     0.2943     0.3968    0.05961         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 2.3it/s 58.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 5.5it/s 2.2s\n                   all         90        937      0.844      0.945      0.938      0.698\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       8/10      4.88G     0.3725     0.3897    0.05988         48        640:   0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       8/10      4.89G     0.2922      0.393    0.05924         64        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 2.3it/s 58.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 5.5it/s 2.2s\n                   all         90        937      0.868      0.903      0.936      0.704\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K       9/10      4.92G     0.3045     0.4325     0.0748         23        640:   0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K       9/10      5.06G     0.2833     0.3822    0.05624         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 2.3it/s 58.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 5.5it/s 2.2s\n                   all         90        937      0.878      0.926      0.948      0.718\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K      10/10       5.2G     0.2679     0.3567    0.06253         41        640:   0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/134  0.4s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K      10/10      5.25G     0.2833     0.3786    0.05978          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 134/134 2.3it/s 58.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 5.5it/s 2.2s\n                   all         90        937      0.881       0.92      0.939      0.714\n\n10 epochs completed in 0.174 hours.\nOptimizer stripped from runs/detect/train/weights/last.pt, 66.1MB\nOptimizer stripped from runs/detect/train/weights/best.pt, 66.1MB\n\nValidating runs/detect/train/weights/best.pt...\nUltralytics 8.3.189 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nrt-detr-l summary: 302 layers, 31,985,795 parameters, 0 gradients, 103.4 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 3.9it/s 3.1s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all         90        937      0.877      0.926      0.948      0.718\nSpeed: 0.2ms preprocess, 30.5ms inference, 0.0ms loss, 0.4ms postprocess per image\nResults saved to \u001b[1mruns/detect/train\u001b[0m\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!zip -r train.zip /kaggle/working/runs/detect/train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:08:49.208049Z","iopub.execute_input":"2025-08-29T19:08:49.208811Z","iopub.status.idle":"2025-08-29T19:08:55.772920Z","shell.execute_reply.started":"2025-08-29T19:08:49.208765Z","shell.execute_reply":"2025-08-29T19:08:55.772129Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/runs/detect/train/ (stored 0%)\n  adding: kaggle/working/runs/detect/train/results.png (deflated 7%)\n  adding: kaggle/working/runs/detect/train/BoxP_curve.png (deflated 16%)\n  adding: kaggle/working/runs/detect/train/BoxF1_curve.png (deflated 15%)\n  adding: kaggle/working/runs/detect/train/args.yaml (deflated 52%)\n  adding: kaggle/working/runs/detect/train/train_batch2.jpg (deflated 4%)\n  adding: kaggle/working/runs/detect/train/val_batch1_pred.jpg (deflated 2%)\n  adding: kaggle/working/runs/detect/train/train_batch1.jpg (deflated 8%)\n  adding: kaggle/working/runs/detect/train/results.csv (deflated 60%)\n  adding: kaggle/working/runs/detect/train/weights/ (stored 0%)\n  adding: kaggle/working/runs/detect/train/weights/last.pt (deflated 8%)\n  adding: kaggle/working/runs/detect/train/weights/best.pt (deflated 8%)\n  adding: kaggle/working/runs/detect/train/val_batch0_pred.jpg (deflated 1%)\n  adding: kaggle/working/runs/detect/train/labels.jpg (deflated 34%)\n  adding: kaggle/working/runs/detect/train/val_batch2_labels.jpg (deflated 2%)\n  adding: kaggle/working/runs/detect/train/confusion_matrix_normalized.png (deflated 37%)\n  adding: kaggle/working/runs/detect/train/confusion_matrix.png (deflated 36%)\n  adding: kaggle/working/runs/detect/train/val_batch1_labels.jpg (deflated 2%)\n  adding: kaggle/working/runs/detect/train/val_batch0_labels.jpg (deflated 2%)\n  adding: kaggle/working/runs/detect/train/BoxR_curve.png (deflated 16%)\n  adding: kaggle/working/runs/detect/train/BoxPR_curve.png (deflated 24%)\n  adding: kaggle/working/runs/detect/train/train_batch0.jpg (deflated 7%)\n  adding: kaggle/working/runs/detect/train/val_batch2_pred.jpg (deflated 1%)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"rtdetr_metrics = rtdetr_finetuned_model.val(data = coco_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:10:53.862612Z","iopub.execute_input":"2025-08-29T19:10:53.863366Z","iopub.status.idle":"2025-08-29T19:11:01.734941Z","shell.execute_reply.started":"2025-08-29T19:10:53.863344Z","shell.execute_reply":"2025-08-29T19:11:01.734268Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.189 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nrt-detr-l summary: 302 layers, 31,985,795 parameters, 0 gradients, 103.4 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.4Â±0.0 ms, read: 136.6Â±34.2 MB/s, size: 61.7 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid/labels... 90 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 994.5it/s 0.1ss\nWARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/top-view-vehicle-detection-image-dataset/Vehicle_Detection_Image_Dataset/valid is not writeable, cache not saved.\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 7.6it/s 3.0s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all         90        937      0.877      0.926      0.948      0.719\nSpeed: 1.4ms preprocess, 27.7ms inference, 0.0ms loss, 0.5ms postprocess per image\nResults saved to \u001b[1mruns/detect/train2\u001b[0m\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"rtdetr_metrics.results_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:11:32.716011Z","iopub.execute_input":"2025-08-29T19:11:32.716310Z","iopub.status.idle":"2025-08-29T19:11:32.723268Z","shell.execute_reply.started":"2025-08-29T19:11:32.716287Z","shell.execute_reply":"2025-08-29T19:11:32.722718Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'metrics/precision(B)': 0.8771930562193498,\n 'metrics/recall(B)': 0.9263607257203842,\n 'metrics/mAP50(B)': 0.9482223044288002,\n 'metrics/mAP50-95(B)': 0.7194915127172211,\n 'fitness': 0.742364591888379}"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}